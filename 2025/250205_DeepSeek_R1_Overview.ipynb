{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HSV-AI/presentations/blob/master/2025/250205_DeepSeek_R1_Overview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA5IOtjsaBIH"
      },
      "source": [
        "![HSV-AI Logo](https://hsv.ai/wp-content/uploads/2022/03/logo_v11_2022.png)\n",
        "\n",
        "## Welcome\n",
        "\n",
        "**Vision** Our vision is a group of individuals and organizations in the metro Huntsville area who collaboratively advance the knowledge and application of artificial intelligence in ways that make it available to everyone and improve our quality of life.\n",
        "\n",
        "How to Connect - [Signup](https://hsv.ai/subscribe)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejIdXRKYbU83"
      },
      "source": [
        "## HudsonAlpha Tech Challenge\n",
        "\n",
        "We should have Tyler Clark stop by for a few minutes to discuss some changes to HATCH and how we can get involved. Otherwise, I can cover based on what I know. The main change from the past challenges is that this will be a one day challenge occurring on Saturday, March 1st."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1DzG_-QbgXC"
      },
      "source": [
        "## AI Symposium\n",
        "\n",
        "We’ll take a few minutes to talk about how the AI Symposium sessions went.  The organizers are interested in feedback for the quality of the sessions and any suggested changes for next year."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtPMm7Uraz51"
      },
      "source": [
        "## SBIR/STTR Topics?\n",
        "\n",
        "The next round of SBIR/STTR Topics are supposed to drop on Wednesday. Given the issues with funding being stopped for NSF grants and other changes driven by the new administration, I don’t know if we will see new topics drop or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geddovf3aucf"
      },
      "source": [
        "## HudsonAlpha Tech Challenge\n",
        "\n",
        "We should have Tyler Clark stop by for a few minutes to discuss some changes to HATCH and how we can get involved. Otherwise, I can cover based on what I know. The main change from the past challenges is that this will be a one day challenge occurring on Saturday, March 1st."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTvDcoS5cQod"
      },
      "source": [
        "\n",
        "## Links & Other Events:\n",
        "\n",
        "- DeepSeek-R1 on GitHub – https://github.com/deepseek-ai/DeepSeek-R1?tab=readme-ov-file\n",
        "- DeepSeek-R1 Paper – https://arxiv.org/pdf/2501.12948\n",
        "- Mixture of Experts Discussion – https://hsv.ai/2023/10/25/mixture-of-experts-harnessing-the-hidden-architecture-of-gpt4/\n",
        "- LLM Distillation Paper - https://arxiv.org/pdf/2410.18588v1\n",
        "- Introduction to AI Slides – https://github.com/HSV-AI/presentations/blob/master/2025/250116_Introduction_to_AI_LearningQuest.pdf\n",
        "- Uses of AI Slides – https://github.com/HSV-AI/presentations/blob/master/2025/250123_Uses_of_AI_LearningQuest.pdf?raw=true\n",
        "- 2025 HATCH – https://hudsonalpha.org/techchallenge/\n",
        "- 2025 BSides – https://nac-issa.org/events/bsides/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t682YJ2EafRh"
      },
      "source": [
        "## DeepSeek-R1\n",
        "\n",
        "![Session Image](https://hsv.ai/wp-content/uploads/2024/12/DeepSeek-R1.png)\n",
        "\n",
        "We’ll be discussing DeepSeek-R1, which has been unavoidable in most conversations over the last week – and rightly so. We will cover the architecture, the approach used for training, as well as the distilled models based on the Llama and Qwen architectures. We have several folks in the group that already have DeepSeek-R1 running locally, so if you need help getting it running or would like to connect directly please let me know.\n",
        "\n",
        "For part of the discussion, you may want to refer back to the Mixture of Experts talk that Josh Phillips led during one of our meetups in October 2023. You can find the link below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW003P7dd9xM"
      },
      "source": [
        "### Key Attributes\n",
        "\n",
        "- Architecture and Scale: It features a Mixture of Experts (MoE) framework with 671 billion parameters, activating 37 billion parameters per query for efficient specialization across domains\n",
        "- Reinforcement Learning (RL): A multi-stage training process integrates RL to refine reasoning and adapt to user feedback, enhancing clarity and relevance\n",
        "- Chain-of-Thought (CoT) Reasoning: It can break down complex queries step-by-step, delivering structured and transparent answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r8JF7pwdxqz"
      },
      "source": [
        "### Distillation\n",
        "\n",
        "DeepSeek uses Llama and Qwen architectures as the foundation for its distilled models, which are compact versions of the larger DeepSeek-R1 model. These models are trained via a distillation process, where the smaller models (e.g., Llama-8B and Qwen-32B) mimic the reasoning capabilities of the original 671B parameter DeepSeek-R1 model.\n",
        "- Llama-Based Models: Variants like DeepSeek-R1-Distill-Llama-8B and Llama-70B are derived from Meta's Llama architecture. They prioritize efficiency and cost-effectiveness while maintaining reasoning capabilities, with larger versions offering closer performance to the original model.\n",
        "- Qwen-Based Models: Models like DeepSeek-R1-Distill-Qwen-1.5B and Qwen-32B are based on Alibaba's Qwen architecture. These models excel in specific tasks such as math and coding, often outperforming other dense models in benchmarks.\n",
        "\n",
        "The distillation approach enables DeepSeek to balance performance, computational efficiency, and scalability across diverse applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN-aRc2_eZ5r"
      },
      "source": [
        "### Hands on Walkthrough\n",
        "\n",
        "For this example, we are going to run a distilled DeepSeek model using vLLM. This requires the use of a T4 instance or higher, as well as the smallest model available to fit within the 15G RAM.\n",
        "\n",
        "We also need to limit the output tokens provided by the model to keep from running out of memory.\n",
        "\n",
        "This should be viewed as a way to get introduced to the model and learn what types of prompts work well, and what generates garbage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "sxjUtMPHKewC",
        "outputId": "336cd61f-2d6a-438e-fcc7-da3f925006a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting vllm\n",
            "  Downloading vllm-0.7.1-cp38-abi3-manylinux1_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\n",
            "Collecting blake3 (from vllm)\n",
            "  Downloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\n",
            "Collecting transformers>=4.48.2 (from vllm)\n",
            "  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (4.25.6)\n",
            "Collecting fastapi!=0.113.*,!=0.114.0,>=0.107.0 (from vllm)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.11.11)\n",
            "Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.59.9)\n",
            "Collecting uvicorn[standard] (from vllm)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.10.6)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.1.0)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
            "  Downloading prometheus_fastapi_instrumentator-7.0.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tiktoken>=0.6.0 (from vllm)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting lm-format-enforcer<0.11,>=0.10.9 (from vllm)\n",
            "  Downloading lm_format_enforcer-0.10.9-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting outlines==0.1.11 (from vllm)\n",
            "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting lark==1.2.2 (from vllm)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xgrammar>=0.1.6 (from vllm)\n",
            "  Downloading xgrammar-0.1.11-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.12.2)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.17.0)\n",
            "Collecting partial-json-parser (from vllm)\n",
            "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.11/dist-packages (from vllm) (24.0.1)\n",
            "Collecting msgspec (from vllm)\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting gguf==0.10.0 (from vllm)\n",
            "  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from vllm) (8.6.1)\n",
            "Collecting mistral_common>=1.5.0 (from mistral_common[opencv]>=1.5.0->vllm)\n",
            "  Downloading mistral_common-1.5.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.0)\n",
            "Collecting compressed-tensors==0.9.0 (from vllm)\n",
            "  Downloading compressed_tensors-0.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting depyf==0.18.0 (from vllm)\n",
            "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\n",
            "Collecting ray>=2.9 (from ray[default]>=2.9->vllm)\n",
            "  Downloading ray-2.42.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting nvidia-ml-py>=12.560.30 (from vllm)\n",
            "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio==2.5.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision==0.20.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.20.1+cu124)\n",
            "Collecting xformers==0.0.28.post3 (from vllm)\n",
            "  Downloading xformers-0.0.28.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting astor (from depyf==0.18.0->vllm)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting dill (from depyf==0.18.0->vllm)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting interegular (from outlines==0.1.11->vllm)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (3.1.5)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
            "Collecting diskcache (from outlines==0.1.11->vllm)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
            "Collecting pycountry (from outlines==0.1.11->vllm)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting airportsdata (from outlines==0.1.11->vllm)\n",
            "  Downloading airportsdata-20241001-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm)\n",
            "  Downloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1->vllm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1->vllm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1->vllm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1->vllm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1->vllm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1->vllm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1->vllm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1->vllm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1->vllm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1->vllm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->vllm) (1.3.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer<0.11,>=0.10.9->vllm) (24.2)\n",
            "Collecting pillow (from vllm)\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting tiktoken>=0.6.0 (from vllm)\n",
            "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mistral_common[opencv]>=1.5.0->vllm) (4.11.0.86)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (2.27.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (8.1.8)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.1.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.5.0)\n",
            "Collecting aiohttp-cors (from ray[default]>=2.9->vllm)\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default]>=2.9->vllm)\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting opencensus (from ray[default]>=2.9->vllm)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.11/dist-packages (from ray[default]>=2.9->vllm) (7.1.0)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default]>=2.9->vllm)\n",
            "  Downloading virtualenv-20.29.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default]>=2.9->vllm)\n",
            "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[default]>=2.9->vllm) (1.70.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.4.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2024.12.14)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.19.1->vllm) (0.27.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.48.2->vllm) (0.5.2)\n",
            "Collecting pybind11 (from xgrammar>=0.1.6->vllm)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from xgrammar>=0.1.6->vllm) (8.3.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->vllm) (3.21.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]->vllm)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (14.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.52.0->vllm) (1.0.7)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (0.22.3)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm)\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm) (4.3.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default]>=2.9->vllm)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: six~=1.16 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default]>=2.9->vllm) (1.17.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default]>=2.9->vllm) (2.19.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->xgrammar>=0.1.6->vllm) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->xgrammar>=0.1.6->vllm) (1.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open->ray[default]>=2.9->vllm) (1.17.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (1.26.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (2.27.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (0.6.1)\n",
            "Downloading vllm-0.7.1-cp38-abi3-manylinux1_x86_64.whl (264.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.2/264.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compressed_tensors-0.9.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading gguf-0.10.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.28.post3-cp311-cp311-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.3/343.3 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.10.9-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.5.2-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.0.2-py3-none-any.whl (18 kB)\n",
            "Downloading ray-2.42.0-cp311-cp311-manylinux2014_x86_64.whl (67.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.4/67.4 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgrammar-0.1.11-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (396 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.9/396.9 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (376 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.29.1-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading airportsdata-20241001-py3-none-any.whl (912 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.7/912.7 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Installing collected packages: py-spy, opencensus-context, nvidia-ml-py, distlib, colorful, blake3, virtualenv, uvloop, uvicorn, python-dotenv, pycountry, pybind11, pillow, partial-json-parser, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, lark, interegular, httptools, gguf, diskcache, dill, astor, airportsdata, watchfiles, tiktoken, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, depyf, prometheus-fastapi-instrumentator, nvidia-cusolver-cu12, lm-format-enforcer, fastapi, aiohttp-cors, transformers, ray, outlines_core, opencensus, mistral_common, xgrammar, xformers, outlines, compressed-tensors, vllm\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "Successfully installed aiohttp-cors-0.7.0 airportsdata-20241001 astor-0.8.1 blake3-1.0.4 colorful-0.5.6 compressed-tensors-0.9.0 depyf-0.18.0 dill-0.3.9 diskcache-5.6.3 distlib-0.3.9 fastapi-0.115.8 gguf-0.10.0 httptools-0.6.4 interegular-0.3.3 lark-1.2.2 lm-format-enforcer-0.10.9 mistral_common-1.5.2 msgspec-0.19.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-ml-py-12.570.86 nvidia-nvjitlink-cu12-12.4.127 opencensus-0.11.4 opencensus-context-0.1.3 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post5 pillow-10.4.0 prometheus-fastapi-instrumentator-7.0.2 py-spy-0.4.0 pybind11-2.13.6 pycountry-24.6.1 python-dotenv-1.0.1 ray-2.42.0 starlette-0.45.3 tiktoken-0.7.0 transformers-4.48.2 uvicorn-0.34.0 uvloop-0.21.0 virtualenv-20.29.1 vllm-0.7.1 watchfiles-1.0.4 xformers-0.0.28.post3 xgrammar-0.1.11\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "819616b9027c45388d03769a12864220",
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Make sure you're on a T4 instance\n",
        "\n",
        "!pip install vllm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "riXIjQa3LtIL"
      },
      "outputs": [],
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "import textwrap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562,
          "referenced_widgets": [
            "a28128f30cc645d59547b993474bb118",
            "9863ade1465d4dd6b58b236d56131538",
            "f8bca98b3f514f22ae71c97b08aa21c4",
            "43b134ef98b44cd690317919228b345a",
            "67800faf361c4448b190d446a345d71b",
            "a4535dde245d42af908ef6bae05b1515",
            "ccf0d29f03c3420fb9bbcbcec1ad3d2f",
            "a1efcbc8746b4cdf8762f04ce7d9a26e",
            "86d1409e56ff4cfcaeb24edeafaf04dd",
            "b308f92e7d314b1aa7f269a08de98b29",
            "992e0c4ac53745e89d808c942b939635",
            "90ca8931e1864840b24e2cf8e5f3042a",
            "23b53939507e49bd9588d7104543f1fd",
            "0a3fda7a20df43ec9f16cce502a87e79",
            "e061b62964004d81bea0b73abfd5bc8f",
            "d8f0b35098a74aeab51eefdff7ea1be0",
            "7e7b7f1935364d65ae42636b39a8d2de",
            "cb4d290568e4421e89bad46b0caf5b9e",
            "49697e5b7e2849c88c3ac50bb4c8678c",
            "8598032ab69744adb81e12f10fdb2885",
            "4ea2bed1262341499f42c154cdbab654",
            "f103d4a538b94eaf968649a8d90a63f0"
          ]
        },
        "collapsed": true,
        "id": "G1soIi3zMos5",
        "outputId": "1a5c40b5-ba70-457e-8a54-0a9ebe104a8e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING 02-05 03:47:37 config.py:2368] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 02-05 03:47:50 config.py:526] This model supports multiple tasks: {'score', 'generate', 'classify', 'embed', 'reward'}. Defaulting to 'generate'.\n",
            "WARNING 02-05 03:47:50 arg_utils.py:1119] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\n",
            "INFO 02-05 03:47:50 config.py:1538] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
            "INFO 02-05 03:47:50 llm_engine.py:232] Initializing a V0 LLM engine (v0.7.1) with config: model='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
            "INFO 02-05 03:47:52 cuda.py:184] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 02-05 03:47:52 cuda.py:232] Using XFormers backend.\n",
            "INFO 02-05 03:47:52 model_runner.py:1111] Starting to load model deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B...\n",
            "INFO 02-05 03:47:53 weight_utils.py:251] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a28128f30cc645d59547b993474bb118",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-05 03:49:21 weight_utils.py:296] No model.safetensors.index.json found in remote.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90ca8931e1864840b24e2cf8e5f3042a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-05 03:49:25 model_runner.py:1116] Loading model weights took 3.3460 GB\n",
            "INFO 02-05 03:49:27 worker.py:266] Memory profiling takes 1.35 seconds\n",
            "INFO 02-05 03:49:27 worker.py:266] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.90) = 13.27GiB\n",
            "INFO 02-05 03:49:27 worker.py:266] model weights take 3.35GiB; non_torch_memory takes 0.05GiB; PyTorch activation peak memory takes 1.39GiB; the rest of the memory reserved for KV Cache is 8.48GiB.\n",
            "INFO 02-05 03:49:28 executor_base.py:108] # CUDA blocks: 19855, # CPU blocks: 9362\n",
            "INFO 02-05 03:49:28 executor_base.py:113] Maximum concurrency for 131072 tokens per request: 2.42x\n",
            "INFO 02-05 03:49:33 model_runner.py:1435] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:30<00:00,  1.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-05 03:50:03 model_runner.py:1563] Graph capturing finished in 30 secs, took 0.19 GiB\n",
            "INFO 02-05 03:50:03 llm_engine.py:429] init engine (profile, create kv cache, warmup model) took 37.59 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "llm = LLM(model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\", dtype=\"half\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v683XU-INNrb",
        "outputId": "05ff6a08-0a51-466f-9523-97b265afe1e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|██████████| 2/2 [01:08<00:00, 34.24s/it, est. speed input: 1.02 toks/s, output: 77.10 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prompt: \n",
            "      Think step by step: How do I travel from Atlanta GA to the Eiffel Tower?\n",
            "    \n",
            "Generated text: \"<think>\\nOkay, so I need to figure out how to travel from Atlanta, GA, to the Eiffel Tower in Paris.\n",
            "I'm not very familiar with this route, but I'll try to break it down step by step.\\n\\nFirst, I think I should find a\n",
            "flight from Atlanta to Paris. I remember hearing that Atlanta is often connected to places like JFK, LAX, or maybe\n",
            "O'Hare International Airport in Chicago. I'll need to check if there's a direct flight from Atlanta to the Eiffel Tower\n",
            "or if I have to go through another city, like Chicago or New York. Maybe the flight is longer, so I might have to pay\n",
            "more, but it's worth considering.\\n\\nNext, after the flight, I'll need to get to the airport in Paris. The Eiffel Tower\n",
            "is in the heart of Paris, so once I arrive, I can walk around to find the building. I think I can find the Eiffel Tower\n",
            "within a few minutes once I'm at the airport, but I should check the traffic to make sure it's easy to find.\\n\\nOnce I'm\n",
            "at the Eiffel Tower, I probably need to take a guided tour. I've heard that there are different types of tours, like a\n",
            "full day tour that includes more history and architecture, or maybe a more casual one with just the Eiffel Tower. I'm\n",
            "not sure which one I prefer, but I think a full day tour might be more informative. I should look up if there are any\n",
            "tour operators or if the Eiffel Tower has its own tours.\\n\\nAfter the tour, I might want to explore the city a bit more.\n",
            "I think the Eiffel Tower is at the heart of Paris, so maybe I can take a nearby attraction like the Louvre Museum or the\n",
            "Eiffel Pyramid. I should plan the rest of my day around these places to make sure I'm not missing out on anything\n",
            "important.\\n\\nI also need to consider the time it takes to get from the airport to the Eiffel Tower. I've heard that\n",
            "it's about an hour or so, but I should double-check the exact duration. Plus, I should make sure the flight is on time\n",
            "to avoid any delays.\\n\\nAnother thing to think about is the cost of the flight. Flights to Paris can be pretty pricey,\n",
            "especially from major cities like Atlanta. I wonder if there are any deals or discounts available for this route. I\n",
            "should also consider other options, like renting a car or taking a train, but I'm not sure if that's cheaper or more\n",
            "convenient.\\n\\nI should also think about the weather. Atlanta is in the southern part of the U.S., so the weather there\n",
            "can be hot and humid. Paris is in the northern part, so it can be cooler and rainy. I should plan for any potential\n",
            "weather issues, maybe packing an umbrella or raincoats.\\n\\nLastly, I need to plan my entire trip. I should schedule the\n",
            "flight, the day trip to the Eiffel Tower, and any other activities in between. I should also make sure to have all my\n",
            "gear ready, like tickets, a map, and any necessary documents for the Eiffel Tower tour.\\n\\nWait, I'm not sure if I\n",
            "should take a bus to the Eiffel Tower from the airport. I think some places offer shuttles or buses, but I'm not\n",
            "certain. I should check if there's a bus option or if I need to take a train or a car instead. Also, I should consider\n",
            "the time it takes for a bus to reach the Eiffel Tower, which I think is about an hour, but maybe it's faster than a\n",
            "train.\\n\\nI'm also wondering if the Eiffel Tower is the best way to get to Paris, or if other attractions like the\n",
            "Eiffel Pyramid or the Louvre are more convenient. I should probably visit the most iconic ones to make the most of the\n",
            "trip.\\n\\nIn summary, my plan is to fly from Atlanta to Paris, perhaps through Chicago, then take a guided tour of the\n",
            "Eiffel Tower, explore nearby attractions, and make sure everything is done on time and within budget.\\n</think>\\n\\nTo\n",
            "travel from Atlanta, GA, to the Eiffel Tower in Paris, follow this organized plan:\\n\\n1. **Flight from Atlanta to\n",
            "Paris**:\\n   - Consider a direct flight from Atlanta (ATL) to Paris (PE) or through Chicago (JFK or LAX).\\n   - Check\n",
            "for the cheapest and fastest flight options, considering flight duration and price.\\n\\n2. **Arrival in Paris**:\\n   -\n",
            "Upon arrival, find the Eiffel Tower within a few minutes by navigating through the airport.\\n\\n3. **Guided Tour of the\n",
            "Eiffel Tower**:\\n   - Book a full day tour to explore the Eiffel Tower's history and architecture, offering a\n",
            "comprehensive experience.\\n\\n4. **Exploration of Nearby Attractions**:\\n   - Visit the Louvre Museum and the Eiffel\n",
            "Pyramid for additional insights into Parisian architecture.\\n\\n5. **Consider Alternative Options**:\\n   - Explore other\n",
            "attractions like the Eiffel Pyramid or the Louvre if the Eiffel Tower tour is preferred.\\n\\n6. **Weather and Time\n",
            "Management**:\\n   - Plan for potential weather, especially with Atlanta's hot and humid weather and Paris's cooler,\n",
            "rainy climate.\\n   - Ensure your travel plan is timed to avoid delays.\\n\\n7. **Travel Gear and Maps**:\\n   - Pack\n",
            "necessary items like tickets, a map, and documents for the Eiffel Tower tour.\\n\\n8. **Final Considerations**:\\n   -\n",
            "Decide on the best route to ensure maximum interest in the trip, focusing on iconic attractions.\\n\\nBy following this\n",
            "plan, you'll efficiently explore Paris, starting from Atlanta, and enjoy the unique journey to the Eiffel Tower.\"\n",
            "\n",
            "Prompt: \n",
            "      Think step by step: Solve this AIME-style problem: Find the sum of all positive integers n less than 1000 such that n^2 + n + 1 is divisible by 7.\n",
            "    \n",
            "Generated text: \"<think>\\nOkay, so I have this problem here: I need to find the sum of all positive integers n less than\n",
            "1000 such that n² + n + 1 is divisible by 7. Hmm, that sounds a bit tricky, but let me try to break it down step by\n",
            "step.\\n\\nFirst, let's understand what the problem is asking. We need to find all n < 1000 where n² + n + 1 is divisible\n",
            "by 7. In other words, n² + n + 1 ≡ 0 mod 7. So, I need to solve the congruence equation n² + n + 1 ≡ 0 mod 7. Once I\n",
            "find all such n, I can sum them up.\\n\\nAlright, so let me think about how to solve this quadratic congruence. I remember\n",
            "that for quadratic equations modulo a prime, there are usually 0, 1, or 2 solutions. Since 7 is a prime, this should be\n",
            "manageable.\\n\\nMaybe I can rewrite the equation to make it easier to handle. Let's see: n² + n + 1 ≡ 0 mod 7. Maybe I\n",
            "can complete the square or factor it somehow. Alternatively, I can test each residue modulo 7 to see which ones satisfy\n",
            "the equation.\\n\\nLet me try the latter approach because it might be more straightforward. Since there are only 7\n",
            "residues modulo 7 (0, 1, 2, 3, 4, 5, 6), I can check each one and see if it satisfies the equation.\\n\\nSo, let's compute\n",
            "n² + n + 1 for each n from 0 to 6 and see if it's congruent to 0 mod 7.\\n\\nStarting with n = 0:\\n0² + 0 + 1 = 1 ≡ 1 mod\n",
            "7. Not 0. So, n=0 is not a solution.\\n\\nn = 1:\\n1² + 1 + 1 = 1 + 1 + 1 = 3 ≡ 3 mod 7. Not 0. So, n=1 is not a\n",
            "solution.\\n\\nn = 2:\\n2² + 2 + 1 = 4 + 2 + 1 = 7 ≡ 0 mod 7. Okay, so n=2 is a solution.\\n\\nn = 3:\\n3² + 3 + 1 = 9 + 3 + 1\n",
            "= 13. 13 mod 7 is 6, which is not 0. So, n=3 is not a solution.\\n\\nn = 4:\\n4² + 4 + 1 = 16 + 4 + 1 = 21. 21 mod 7 is 0.\n",
            "So, n=4 is a solution.\\n\\nn = 5:\\n5² + 5 + 1 = 25 + 5 + 1 = 31. 31 mod 7 is 3 (since 7*4=28, 31-28=3). Not 0. So, n=5 is\n",
            "not a solution.\\n\\nn = 6:\\n6² + 6 + 1 = 36 + 6 + 1 = 43. 43 mod 7: 7*6=42, so 43-42=1. Not 0. So, n=6 is not a\n",
            "solution.\\n\\nAlright, so from 0 to 6, the solutions are n=2 and n=4. So, every 7 numbers, the solutions repeat. That\n",
            "means the solutions are all integers congruent to 2 or 4 mod 7.\\n\\nSo, in other words, n ≡ 2 mod 7 or n ≡ 4 mod 7. So, n\n",
            "can be written as 7k + 2 or 7k + 4 for some integer k ≥ 0.\\n\\nNow, since we need n < 1000, let's find all such\n",
            "n.\\n\\nFirst, let's consider n = 7k + 2. We need 7k + 2 < 1000. So, 7k < 998. Therefore, k < 998/7. Let's compute 998\n",
            "divided by 7.\\n\\n7*142 = 994. So, 998 - 994 = 4. So, 998/7 = 142 + 4/7 ≈ 142.571. So, k can be from 0 to 142. But wait,\n",
            "7k + 2 < 1000. So, k can be from 0 up to floor((999 - 2)/7) = floor(997/7). Let's compute 997 divided by 7.\\n\\n7*142 =\n",
            "994, so 997 - 994 = 3. So, 997/7 = 142 + 3/7. So, floor(997/7) is 142. So, k can be 0,1,2,...,142. That is 143 values of\n",
            "k.\\n\\nSimilarly, for n = 7k + 4. We need 7k + 4 < 1000. So, 7k < 996. Therefore, k < 996/7. Let's compute 996 divided by\n",
            "7.\\n\\n7*142 = 994, so 996 - 994 = 2. So, 996/7 = 142 + 2/7. So, floor(996/7) is 142. So, k can be from 0 to 142. That is\n",
            "143 values of k.\\n\\nWait, hold on. For n = 7k + 4, 7k + 4 < 1000, so 7k < 996, so k < 996/7 ≈ 142.285. So, k can be up\n",
            "to 142 as well. So, same number of k's.\\n\\nTherefore, total number of solutions is 143 + 143 = 286. Hmm, but let me\n",
            "verify this because sometimes when you have overlapping or different starting points, you might have an off-by-one\n",
            "error.\\n\\nWait, actually, let's think differently. Since n can be congruent to 2 or 4 mod 7, each residue class mod 7\n",
            "contributes equally to the total count. So, in the range from 0 to 6, two residues satisfy the condition. So, in each\n",
            "block of 7 consecutive numbers, there are 2 solutions.\\n\\nTherefore, in the range 0 to 699 (since 7*100=700), there\n",
            "would be 100 blocks, each contributing 2 solutions, so 200 solutions. But wait, our upper limit is 999, not 700. So,\n",
            "perhaps we need to adjust for the remaining numbers.\\n\\nWait, actually, 7*142=994, so 994 is the last number before\n",
            "1000. Then, the next number is 995, which is 7*142 +1, 996=7*142+2, 997=7*142+3, 998=7*142+4, 999=7*142+5. So, from\n",
            "7*142 +2 to 7*142 +5, which are 996,997,998,999, that's 4 numbers. So, in these 4 numbers, n=996,997,998,999, only n=996\n",
            "is 7*142 +4, which is a solution. So, in each block of 7 numbers, 2 solutions, except the last partial block where only\n",
            "1 solution exists.\\n\\nWait, so let me compute how many full blocks of 7 are there below 1000.\\n\\n1000 divided by 7 is\n",
            "approximately 142.857. So, 142 full blocks, and then a partial block of 6 numbers (from 994 +1 to 994 +6, which is 995\n",
            "to 999). So, in each full block, 2 solutions. So, 142 blocks * 2 solutions = 284 solutions. Then, in the partial block,\n",
            "we have n=995,996,997,998,999,1000. Wait, but n must be less than 1000, so n=999 is the last. So, in the partial block,\n",
            "n=996,997,998,999. From these, n=996 and n=999: but wait, n=996 is 7*142 +4, which is a solution, but n=999 is 7*142 +5,\n",
            "which is not a solution. So, only n=996 is a solution in the partial block.\\n\\nTherefore, total solutions: 142 blocks *\n",
            "2 solutions = 284, plus 1 solution in the last partial block, totaling 285 solutions. Wait, but earlier I thought 286,\n",
            "but this seems 285. Hmm, let me check.\\n\\nWait, maybe I made a mistake in the count of the partial block. The numbers\n",
            "from 995 to 999 are 5 numbers: 995,996,997,998,999. So, n=996 is a solution, n=997 is not, n=998 is not, n=999 is not.\n",
            "So, only 1 solution in the partial block.\\n\\nTherefore, total solutions: 142 blocks * 2 solutions = 284, plus 1\n",
            "solution, totaling 285 solutions.\\n\\nWait, but 142 blocks would be 142*7=994, so the next block starts at 995, so\n",
            "n=995,996,...,999, which are 5 numbers. So, in each block, 2 solutions. So, 142 blocks give 142*2=284 solutions, and in\n",
            "the partial block, 1 solution. So, total 285 solutions.\\n\\nWait, but when I considered n=7k +2 and n=7k +4, for k from 0\n",
            "to 142, but 7k +4 when k=142 is 7*142 +4=988 +4=992, which is less than 1000. Wait, hold on, 7*142=994, so 7*142 +4=998.\n",
            "Wait, no, 7*142 is 994, so 7*142 +4=998, which is less than 1000. So, that's 143 solutions for each residue.\\n\\nWait,\n",
            "wait, perhaps I confused the counts earlier. Let me think again.\\n\\nWhen k=0: 7*0 +2=2, 7*0 +4=4\\n\\nk=1:\n",
            "9,11\\n\\n...\\n\\nk=142: 7*142 +2=994 +2=996, 7*142 +4=994 +4=998\\n\\nSo, for n=7k +2, k ranges from 0 to 142, inclusive,\n",
            "which is 143 terms.\\n\\nSimilarly, for n=7k +4, k ranges from 0 to 142, inclusive, which is 143 terms.\\n\\nSo, total\n",
            "solutions: 143 + 143=286.\\n\\nBut earlier, I thought that in the last partial block, only one solution exists, but\n",
            "according to this, n=7k +4 for k=142 is 998, which is less than 1000, so that's a solution. Then, n=7k +2 for k=142 is\n",
            "996, which is also less than 1000. So, both 996 and 998 are solutions, so that's two solutions in the last partial\n",
            "block.\\n\\nWait, so in each block, 2 solutions, so 142 blocks give 284 solutions, and the last partial block gives 2\n",
            "solutions, so total 286.\\n\\nWait, but when I considered k from 0 to 142, that includes k=142, which gives n=998, which\n",
            "is less than 1000, so that's a valid solution. So, 143 solutions for each residue, so 286 in total.\\n\\nBut earlier, when\n",
            "I thought about the partial block, I thought only n=996 is a solution, but actually, both n=996 and n=998 are solutions,\n",
            "so that's two solutions in the partial block. So, 142 blocks * 2 = 284, plus 2 solutions in the partial block, totaling\n",
            "286.\\n\\nWait, but let me think about the numbers. Let's list the numbers less than 1000 that are congruent to 2 or 4 mod\n",
            "7.\\n\\nFirst, numbers congruent to 2 mod 7: starting at 2, then 9, 16, ..., up to the largest number less than\n",
            "1000.\\n\\nSimilarly, numbers congruent to 4 mod 7: starting at 4, then 11, 18, ..., up to the largest number less than\n",
            "1000.\\n\\nSo, to compute how many terms each of these sequences has.\\n\\nFor numbers congruent to 2 mod 7:\\n\\nThe first\n",
            "term is 2, the last term is the largest number less than 1000 congruent to 2 mod 7.\\n\\nCompute 1000 divided by 7: 1000\n",
            "/7=142.857, so 142*7=994, so 994 +2=996.\\n\\nSo, the last term is 996.\\n\\nSo, the sequence is 2,9,16,...,996.\\n\\nThis is\n",
            "an arithmetic sequence with first term a=2, common difference d=7, last term l=996.\\n\\nNumber of terms: n = ((l - a)/d)\n",
            "+1 = ((996 -2)/7)+1 = (994/7)+1=142 +1=143 terms.\\n\\nSimilarly, for numbers congruent to 4 mod 7:\\n\\nFirst term is 4,\n",
            "last term is the largest number less than 1000 congruent to 4 mod 7.\\n\\nCompute 1000 - (1000 mod 7). Since 1000 mod 7 is\n",
            "2, so 1000 -2=998. So, 998 is 4 mod7.\\n\\nWait, 998 divided by7: 7*142=994, so 998=994 +4, so yes, 998 is 4 mod7.\\n\\nSo,\n",
            "the last term is 998.\\n\\nSo, the sequence is 4,11,18,...,998.\\n\\nNumber of terms: n= ((998 -4)/7)+1= (994/7)+1=142\n",
            "+1=143 terms.\\n\\nTherefore, both sequences have 143 terms each, so total solutions are 143 +143=286.\\n\\nWait, so earlier\n",
            "I was confused about whether the partial block had 1 solution or 2, but actually, in the partial block from 995 to 999,\n",
            "only n=996 is a solution, but n=998 is also a solution, which is included in the next block. So, in the last partial\n",
            "block, only n=996 is a solution, but n=998 is in the next block. So, in the last partial block, only 1\n",
            "solution.\\n\\nWait, but 995 is not a solution, 996 is a solution, 997 is not, 998 is a solution, 999 is not.\\n\\nSo, in\n",
            "the last partial block, from 995 to 999, only n=996 and n=998 are solutions, but n=998 is in the next block, so only\n",
            "n=996 is a solution in the last partial block.\\n\\nWait, so if I count the number of solutions in each block, the first\n",
            "142 blocks each contribute 2 solutions, and the last partial block contributes 1 solution, so total 285\n",
            "solutions.\\n\\nBut according to the arithmetic sequence counts, both sequences have 143 terms, so 286 in total. Hmm, so\n",
            "there seems to be a discrepancy here.\\n\\nWait, let me check: 143 blocks of 7 numbers each would cover 991 numbers,\n",
            "right? Because 143*7=1001, which is more than 1000. So, 143 blocks would go up to 991 +7=998, which is 143*7=991, next\n",
            "block is 992-1000. So, in the 143 blocks, how many numbers are there? 143*7=991 numbers, from 0 to 991, but n needs to\n",
            "be less than 1000, so 0 to 999.\\n\\nWait, perhaps I'm complicating this. Let me think in terms of how many numbers less\n",
            "than 1000 are congruent to 2 mod7 and 4 mod7.\\n\\nFor numbers congruent to 2 mod7: starting at 2, then 9, 16,..., up to\n",
            "996.\\n\\nSimilarly, numbers congruent to 4 mod7: starting at 4,11,...,998.\\n\\nSo, each arithmetic sequence\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "prompts = [\n",
        "    \"\"\"\n",
        "      Think step by step: How do I travel from Atlanta GA to the Eiffel Tower?\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "      Think step by step: Solve this AIME-style problem: Find the sum of all positive integers n less than 1000 such that n^2 + n + 1 is divisible by 7.\n",
        "    \"\"\"\n",
        "]\n",
        "\n",
        "sampling_params = SamplingParams(temperature=0.6, top_p=0.95, max_tokens=4096)\n",
        "\n",
        "outputs = llm.generate(prompts, sampling_params)\n",
        "\n",
        "for output in outputs:\n",
        "    prompt = output.prompt\n",
        "    generated_text = output.outputs[0].text\n",
        "    print(f\"\\nPrompt: {prompt}\")\n",
        "    # Wrap the text\n",
        "    wrapped_text = textwrap.fill(f\"Generated text: {generated_text!r}\", width=120)\n",
        "\n",
        "    # Print the wrapped text\n",
        "    print(wrapped_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_H0LXE5Qf97"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QWUpLlga-6F"
      },
      "source": [
        "## Paper Review Series\n",
        "\n",
        "This year we are going to start a review series to look at published papers in-depth. These will be a monthly, virtual-only meetup to start with but may shift based on interest. The first paper review will be on Wednesday, February 12, led by Josh Phillips to cover the DeepSeek-R1 paper (also linked below)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMlnt8ufpXFKvvs6IzDNotp",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a3fda7a20df43ec9f16cce502a87e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49697e5b7e2849c88c3ac50bb4c8678c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8598032ab69744adb81e12f10fdb2885",
            "value": 1
          }
        },
        "23b53939507e49bd9588d7104543f1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e7b7f1935364d65ae42636b39a8d2de",
            "placeholder": "​",
            "style": "IPY_MODEL_cb4d290568e4421e89bad46b0caf5b9e",
            "value": ""
          }
        },
        "43b134ef98b44cd690317919228b345a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b308f92e7d314b1aa7f269a08de98b29",
            "placeholder": "​",
            "style": "IPY_MODEL_992e0c4ac53745e89d808c942b939635",
            "value": " 3.55G/3.55G [01:27&lt;00:00, 40.8MB/s]"
          }
        },
        "49697e5b7e2849c88c3ac50bb4c8678c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ea2bed1262341499f42c154cdbab654": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67800faf361c4448b190d446a345d71b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e7b7f1935364d65ae42636b39a8d2de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8598032ab69744adb81e12f10fdb2885": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86d1409e56ff4cfcaeb24edeafaf04dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90ca8931e1864840b24e2cf8e5f3042a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23b53939507e49bd9588d7104543f1fd",
              "IPY_MODEL_0a3fda7a20df43ec9f16cce502a87e79",
              "IPY_MODEL_e061b62964004d81bea0b73abfd5bc8f"
            ],
            "layout": "IPY_MODEL_d8f0b35098a74aeab51eefdff7ea1be0"
          }
        },
        "9863ade1465d4dd6b58b236d56131538": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4535dde245d42af908ef6bae05b1515",
            "placeholder": "​",
            "style": "IPY_MODEL_ccf0d29f03c3420fb9bbcbcec1ad3d2f",
            "value": "model.safetensors: 100%"
          }
        },
        "992e0c4ac53745e89d808c942b939635": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1efcbc8746b4cdf8762f04ce7d9a26e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a28128f30cc645d59547b993474bb118": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9863ade1465d4dd6b58b236d56131538",
              "IPY_MODEL_f8bca98b3f514f22ae71c97b08aa21c4",
              "IPY_MODEL_43b134ef98b44cd690317919228b345a"
            ],
            "layout": "IPY_MODEL_67800faf361c4448b190d446a345d71b"
          }
        },
        "a4535dde245d42af908ef6bae05b1515": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b308f92e7d314b1aa7f269a08de98b29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb4d290568e4421e89bad46b0caf5b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccf0d29f03c3420fb9bbcbcec1ad3d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8f0b35098a74aeab51eefdff7ea1be0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e061b62964004d81bea0b73abfd5bc8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ea2bed1262341499f42c154cdbab654",
            "placeholder": "​",
            "style": "IPY_MODEL_f103d4a538b94eaf968649a8d90a63f0",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:04&lt;00:00,  4.10s/it]\n"
          }
        },
        "f103d4a538b94eaf968649a8d90a63f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8bca98b3f514f22ae71c97b08aa21c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1efcbc8746b4cdf8762f04ce7d9a26e",
            "max": 3554214621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86d1409e56ff4cfcaeb24edeafaf04dd",
            "value": 3554214621
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
