{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6.7 64-bit ('anaconda': virtualenv)",
      "language": "python",
      "name": "python36764bitanacondavirtualenvb58dd6c6b1a94502be7b539be867f03a"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "210217_Recommendation_Systems.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HSV-AI/presentations/blob/master/2021/210217_Recommendation_Systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQq3RxmsIlO3"
      },
      "source": [
        "![HSV-AI Logo](https://github.com/HSV-AI/hugo-website/blob/master/static/images/logo_v9.png?raw=true)\r\n",
        "\r\n",
        "# Quick Start for Recommendation Systems\r\n",
        "\r\n",
        "Agenda:\r\n",
        "- Welcome\r\n",
        "- Project updates\r\n",
        "- Current news\r\n",
        "- Presentation on Recommendation Systems\r\n",
        "- Q&A\r\n",
        "- Close\r\n",
        "\r\n",
        "We will start with a common dataset used for exploring recommendation systems, the [MovieLens Dataset](http://grouplens.org/datasets/movielens/)\r\n",
        "\r\n",
        "We will also use the [Surprise](http://surpriselib.com/) library to build a few different recommendation systems and look at their accuracy for the dataset.\r\n",
        "\r\n",
        "The name SurPRISE (roughly :) ) stands for Simple Python RecommendatIon System Engine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpX_iOxJGIvm",
        "outputId": "971be3de-24a4-46d4-db9a-d4abdac2f5be"
      },
      "source": [
        "!pip install scikit-surprise"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.0.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyCwlfohPsJC"
      },
      "source": [
        "# Global imports\r\n",
        "import pandas as pd\r\n",
        "import io\r\n",
        "from collections import defaultdict\r\n",
        "from surprise import SVD\r\n",
        "from surprise import Dataset\r\n",
        "from surprise.model_selection import cross_validate\r\n",
        "from surprise.model_selection import KFold\r\n",
        "from surprise import KNNBasic\r\n",
        "from surprise import get_dataset_dir\r\n",
        "from surprise import dump"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCyu3JyDGIvm"
      },
      "source": [
        "# Load the movielens-100k dataset (download it if needed),\n",
        "data = Dataset.load_builtin('ml-100k')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s5KlfFXREu5"
      },
      "source": [
        "## Looking at the data\r\n",
        "\r\n",
        "u.data     -- The full u data set, 100000 ratings by 943 users on 1682 items.\r\n",
        "\r\n",
        "- Each user has rated at least 20 movies.\r\n",
        "- Users and items are numbered consecutively from 1.\r\n",
        "- The data is randomly ordered.\r\n",
        "- This is a tab separated list of user id | item id | rating | timestamp. \r\n",
        "- The time stamps are unix seconds since 1/1/1970 UTC\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "LYI6LPGYQraD",
        "outputId": "0a2c4413-eef0-4251-a224-c06e88f41c04"
      },
      "source": [
        "data_df = pd.read_table('/root/.surprise_data/ml-100k/ml-100k/u.data', header=None)\r\n",
        "data_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1  2          3\n",
              "0  196  242  3  881250949\n",
              "1  186  302  3  891717742\n",
              "2   22  377  1  878887116\n",
              "3  244   51  2  880606923\n",
              "4  166  346  1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r72iYn0VTdAk"
      },
      "source": [
        "u.item     -- Information about the items (movies); \r\n",
        "- this is a tab separated list of\r\n",
        "              movie id | movie title | release date | video release date |\r\n",
        "              IMDb URL | unknown | Action | Adventure | Animation |\r\n",
        "              Children's | Comedy | Crime | Documentary | Drama | Fantasy |\r\n",
        "              Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |\r\n",
        "              Thriller | War | Western |\r\n",
        "- The last 19 fields are the genres, a 1 indicates the movie is of that genre, a 0 indicates it is not\r\n",
        "- movies can be in several genres at once.\r\n",
        "- The movie ids are the ones used in the u.data data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9yeH7OhTRikS",
        "outputId": "67556e97-b014-46d3-9067-8747522a8b06"
      },
      "source": [
        "item_df = pd.read_csv('/root/.surprise_data/ml-100k/ml-100k/u.item', sep=\"|\", encoding='iso-8859-1', header=None)\r\n",
        "item_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>GoldenEye (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Four Rooms (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Get Shorty (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Copycat (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0                  1            2   3   ... 20  21  22  23\n",
              "0   1   Toy Story (1995)  01-Jan-1995 NaN  ...  0   0   0   0\n",
              "1   2   GoldenEye (1995)  01-Jan-1995 NaN  ...  0   1   0   0\n",
              "2   3  Four Rooms (1995)  01-Jan-1995 NaN  ...  0   1   0   0\n",
              "3   4  Get Shorty (1995)  01-Jan-1995 NaN  ...  0   0   0   0\n",
              "4   5     Copycat (1995)  01-Jan-1995 NaN  ...  0   1   0   0\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEr2_fVnT3ll"
      },
      "source": [
        "u.user     -- Demographic information about the users\r\n",
        "- this is a tab separated list of\r\n",
        "              user id | age | gender | occupation | zip code\r\n",
        "- The user ids are the ones used in the u.data data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "qSvS0w07Szve",
        "outputId": "c3ff16c7-9158-4620-d950-baba6af233a6"
      },
      "source": [
        "user_df = pd.read_csv('/root/.surprise_data/ml-100k/ml-100k/u.user', sep=\"|\", encoding='iso-8859-1', header=None)\r\n",
        "user_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>M</td>\n",
              "      <td>technician</td>\n",
              "      <td>85711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>53</td>\n",
              "      <td>F</td>\n",
              "      <td>other</td>\n",
              "      <td>94043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>M</td>\n",
              "      <td>writer</td>\n",
              "      <td>32067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>M</td>\n",
              "      <td>technician</td>\n",
              "      <td>43537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>33</td>\n",
              "      <td>F</td>\n",
              "      <td>other</td>\n",
              "      <td>15213</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0   1  2           3      4\n",
              "0  1  24  M  technician  85711\n",
              "1  2  53  F       other  94043\n",
              "2  3  23  M      writer  32067\n",
              "3  4  24  M  technician  43537\n",
              "4  5  33  F       other  15213"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca5LFHpYXuTo"
      },
      "source": [
        "## Types of Recommendation Systems (From Wikipedia)\r\n",
        "\r\n",
        "Other references used:\r\n",
        "\r\n",
        "[Memory Based Recommendation System](https://towardsdatascience.com/how-to-build-a-memory-based-recommendation-system-using-python-surprise-55f3257b2cf4)\r\n",
        "\r\n",
        "[Model Based Recommendation System](https://towardsdatascience.com/how-to-build-a-model-based-recommendation-system-using-python-surprise-2df3b77ab3e5)\r\n",
        "\r\n",
        "### Collaborative Filtering\r\n",
        "\r\n",
        "> Collaborative filtering is based on the assumption that people who agreed in the past will agree in the future, and that they will like similar kinds of items as they liked in the past. The system generates recommendations using only information about rating profiles for different users or items. By locating peer users/items with a rating history similar to the current user or item, they generate recommendations using this neighborhood. Collaborative filtering methods are classified as memory-based and model-based.\r\n",
        "\r\n",
        "> #### Memory Based\r\n",
        "\r\n",
        "> They are called memory-based because the algorithm is not complicated, but requires a lot of memory to keep track of the results.\r\n",
        "\r\n",
        "> #### Model Based\r\n",
        "\r\n",
        "> Model Based approaches build some type of machine learning model. For the surprise package, there are three models avaialble: SVD, SVDpp, and NMF.\r\n",
        "\r\n",
        "> #### Problems with Collaborative Filtering\r\n",
        "\r\n",
        "> - Cold start: For a new user or item, there isn't enough data to make accurate recommendations.\r\n",
        "- Scalability: In many of the environments in which these systems make recommendations, there are millions of users and products. Thus, a large amount of computation power is often necessary to calculate recommendations.\r\n",
        "- Sparsity: The number of items sold on major e-commerce sites is extremely large. The most active users will only have rated a small subset of the overall database. Thus, even the most popular items have very few ratings.\r\n",
        "\r\n",
        "### Content Based Filtering\r\n",
        "\r\n",
        "> Content-based filtering methods are based on a description of the item and a profile of the user's preferences. These methods are best suited to situations where there is known data on an item (name, location, description, etc.), but not on the user. Content-based recommenders treat recommendation as a user-specific classification problem and learn a classifier for the user's likes and dislikes based on an item's features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGAzk7SRMXy2"
      },
      "source": [
        "## Assessing Model Performance\r\n",
        "\r\n",
        "### Accuracy measures\r\n",
        "\r\n",
        "- rmse\tCompute RMSE (Root Mean Squared Error).\r\n",
        "- mse\tCompute MSE (Mean Squared Error).\r\n",
        "- mae\tCompute MAE (Mean Absolute Error).\r\n",
        "- fcp\tCompute FCP (Fraction of Concordant Pairs).\r\n",
        "\r\n",
        "### Precision and Recall\r\n",
        "\r\n",
        "\r\n",
        "![precision](https://wikimedia.org/api/rest_v1/media/math/render/svg/5b7d5cd5010efe2ef51e7731f2124a2156830fbe)\r\n",
        "\r\n",
        "![recall](https://wikimedia.org/api/rest_v1/media/math/render/svg/43a4548e95fde15433d8e3cd3c80ced433f54abe)\r\n",
        "\r\n",
        "An item is considered relevant if its true rating rui is greater than a given threshold. An item is considered recommended if its estimated rating r^ui is greater than the threshold, and if it is among the k highest estimated ratings.\r\n",
        "\r\n",
        "Note that in the edge cases where division by zero occurs, Precision@k and Recall@k values are undefined. As a convention, we set their values to 0 in such cases.\r\n",
        "\r\n",
        "One can also interpret precision and recall not as ratios but as estimations of probabilities:\r\n",
        "\r\n",
        "- Precision is the estimated probability that a document randomly selected from the pool of retrieved documents is relevant.\r\n",
        "\r\n",
        "- Recall is the estimated probability that a document randomly selected from the pool of relevant documents is retrieved.\r\n",
        "\r\n",
        "Another interpretation is that precision is the average probability of relevant retrieval and recall is the average probability of complete retrieval averaged over multiple retrieval queries.\r\n",
        "\r\n",
        "### F-Score\r\n",
        "\r\n",
        "The F-score is a measure of a test's accuracy. It is calculated from the precision and recall of the test, where the precision is the number of correctly identified positive results divided by the number of all positive results, including those not identified correctly, and the recall is the number of correctly identified positive results divided by the number of all samples that should have been identified as positive.\r\n",
        "\r\n",
        "![f-score](https://wikimedia.org/api/rest_v1/media/math/render/svg/9c94f59b68f5ae0dc92185906c7ec4214fd04e1e)\r\n",
        "\r\n",
        "The highest possible value of an F-score is 1.0, indicating perfect precision and recall, and the lowest possible value is 0, if either the precision or the recall is zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRIG4-awyQiY"
      },
      "source": [
        "def get_f_score(precision, recall):\r\n",
        "  denominator = precision + recall\r\n",
        "  if(denominator == 0):\r\n",
        "    return 0\r\n",
        "  return 2 * (precision * recall) / denominator"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9Sw4f1wXZ_u"
      },
      "source": [
        "## Memory Based\r\n",
        "\r\n",
        "For now, we will start with a memory based approach using one of the algorithms provided by the suprise library.\r\n",
        "\r\n",
        "We will start with the KNNBasic algorithm. It takes a sim_option as a parameter:\r\n",
        "\r\n",
        "This argument is a dictionary with the following (all optional) keys:\r\n",
        "\r\n",
        "- 'name': The name of the similarity to use, as defined in the similarities module. Default is 'MSD'.\r\n",
        "- 'user_based': Whether similarities will be computed between users or between items. This has a huge impact on the performance of a prediction algorithm. Default is True.\r\n",
        "- 'min_support': The minimum number of common items (when 'user_based' is 'True') or minimum number of common users (when 'user_based' is 'False') for the similarity not to be zero.\r\n",
        "- 'shrinkage': Shrinkage parameter to apply (only relevant for pearson_baseline similarity). Default is 100.\r\n",
        "\r\n",
        "\r\n",
        "KNNBasic parameters:\r\n",
        "\r\n",
        "- k (int) – The (max) number of neighbors to take into account for aggregation (see this note). Default is 40.\r\n",
        "- min_k (int) – The minimum number of neighbors to take into account for aggregation. If there are not enough neighbors, the neighbor aggregation is set to zero (so the prediction ends up being equivalent to the mean μu or μi). Default is 1.\r\n",
        "- sim_options (dict) – A dictionary of options for the similarity measure. See Similarity measure configuration for accepted options.\r\n",
        "- verbose (bool) – Whether to print trace messages of bias estimation, similarity, etc. Default is True."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJQScQQqPKvd"
      },
      "source": [
        "my_k = 15\r\n",
        "my_min_k = 5\r\n",
        "my_sim_option = {\r\n",
        "    'name':'cosine', 'user_based':False, \r\n",
        "    }\r\n",
        "\r\n",
        "algo = KNNBasic(\r\n",
        "    k = my_k, min_k = my_min_k, sim_option = my_sim_option, verbose = False\r\n",
        "    )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kh1uMHqGIvn",
        "outputId": "c7d0e47a-fedf-4f3f-b692-3fb3535c4495"
      },
      "source": [
        "\r\n",
        "# Run 5-fold cross-validation and print results\r\n",
        "results = cross_validate(algo, data, measures=['RMSE', 'MSE', 'MAE', 'FCP'], cv=5, verbose=True)\r\n",
        "\r\n",
        "# You can get several of the items specifically from the returned results. Very\r\n",
        "# useful if you need to wrap this in a grid search"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating RMSE, MSE, MAE, FCP of algorithm KNNBasic on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9751  0.9835  0.9873  0.9841  0.9777  0.9815  0.0045  \n",
            "MSE (testset)     0.9508  0.9673  0.9748  0.9685  0.9559  0.9635  0.0088  \n",
            "MAE (testset)     0.7708  0.7752  0.7768  0.7779  0.7707  0.7743  0.0030  \n",
            "FCP (testset)     0.7014  0.6958  0.7053  0.6993  0.6953  0.6994  0.0037  \n",
            "Fit time          0.46    0.38    0.37    0.38    0.40    0.40    0.03    \n",
            "Test time         2.68    2.62    2.69    2.82    2.66    2.69    0.07    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLs3318TN88v",
        "outputId": "35d4c512-5d0e-41d0-eb14-6075980aec62"
      },
      "source": [
        "algo.predict(uid = '244', iid = '2')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Prediction(uid='244', iid='2', r_ui=None, est=2.9444778707559003, details={'actual_k': 15, 'was_impossible': False})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfWBEoxDabER",
        "outputId": "cccb7301-113a-4905-c27e-be47c608f675"
      },
      "source": [
        "def get_top_n(predictions, n=10):\r\n",
        "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\r\n",
        "\r\n",
        "    Args:\r\n",
        "        predictions(list of Prediction objects): The list of predictions, as\r\n",
        "            returned by the test method of an algorithm.\r\n",
        "        n(int): The number of recommendation to output for each user. Default\r\n",
        "            is 10.\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    A dict where keys are user (raw) ids and values are lists of tuples:\r\n",
        "        [(raw item id, rating estimation), ...] of size n.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # First map the predictions to each user.\r\n",
        "    top_n = defaultdict(list)\r\n",
        "    for uid, iid, true_r, est, _ in predictions:\r\n",
        "        top_n[uid].append((iid, est))\r\n",
        "\r\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones.\r\n",
        "    for uid, user_ratings in top_n.items():\r\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\r\n",
        "        top_n[uid] = user_ratings[:n]\r\n",
        "\r\n",
        "    return top_n\r\n",
        "\r\n",
        "trainset = data.build_full_trainset()\r\n",
        "\r\n",
        "algo.fit(trainset)\r\n",
        "\r\n",
        "# Then predict ratings for all pairs (u, i) that are NOT in the training set.\r\n",
        "testset = trainset.build_anti_testset()\r\n",
        "predictions = algo.test(testset)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDFXkAXXjTC6",
        "outputId": "a259a97e-bdef-41f2-95e4-b1d156f67099"
      },
      "source": [
        "print(predictions[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "user: 196        item: 302        r_ui = 3.53   est = 4.16   {'actual_k': 15, 'was_impossible': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olttOd1Ejx9t"
      },
      "source": [
        "top_n = get_top_n(predictions, n=10)\r\n",
        "\r\n",
        "# Print the recommended items for each user\r\n",
        "for uid, user_ratings in top_n.items():\r\n",
        "    print(uid, [iid for (iid, _) in user_ratings])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19H2pIFxkIL-"
      },
      "source": [
        "def precision_recall_at_k(predictions, k=10, threshold=3.5):\r\n",
        "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\r\n",
        "\r\n",
        "    # First map the predictions to each user.\r\n",
        "    user_est_true = defaultdict(list)\r\n",
        "    for uid, _, true_r, est, _ in predictions:\r\n",
        "        user_est_true[uid].append((est, true_r))\r\n",
        "\r\n",
        "    precisions = dict()\r\n",
        "    recalls = dict()\r\n",
        "    for uid, user_ratings in user_est_true.items():\r\n",
        "\r\n",
        "        # Sort user ratings by estimated value\r\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\r\n",
        "\r\n",
        "        # Number of relevant items\r\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\r\n",
        "\r\n",
        "        # Number of recommended items in top k\r\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\r\n",
        "\r\n",
        "        # Number of relevant and recommended items in top k\r\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\r\n",
        "                              for (est, true_r) in user_ratings[:k])\r\n",
        "\r\n",
        "        # Precision@K: Proportion of recommended items that are relevant\r\n",
        "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\r\n",
        "\r\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\r\n",
        "\r\n",
        "        # Recall@K: Proportion of relevant items that are recommended\r\n",
        "        # When n_rel is 0, Recall is undefined. We here set it to 0.\r\n",
        "\r\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\r\n",
        "\r\n",
        "    return precisions, recalls"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIebvQBIp6z_",
        "outputId": "656971d4-0248-4c14-b130-48cfa565d27b"
      },
      "source": [
        "kf = KFold(n_splits=5)\r\n",
        "\r\n",
        "algo = KNNBasic(\r\n",
        "    k = my_k, min_k = my_min_k, sim_option = my_sim_option, verbose = False\r\n",
        "    )\r\n",
        "\r\n",
        "for trainset, testset in kf.split(data):\r\n",
        "    algo.fit(trainset)\r\n",
        "    predictions = algo.test(testset)\r\n",
        "    precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=4)\r\n",
        "\r\n",
        "    # Precision and recall can then be averaged over all users\r\n",
        "    precision = sum(prec for prec in precisions.values()) / len(precisions)\r\n",
        "    recall = sum(rec for rec in recalls.values()) / len(recalls)\r\n",
        "    fscore = get_f_score(precision, recall)\r\n",
        "    print('Precision:', precision, 'Recall:', recall, 'F1 Score', fscore)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.6915605095541413 Recall: 0.2545407464983976 F1 Score 0.37211731244324237\n",
            "Precision: 0.6856205673758871 Recall: 0.26644216627606115 F1 Score 0.38375250444754067\n",
            "Precision: 0.6823082361258408 Recall: 0.2673883124151236 F1 Score 0.3842095626964549\n",
            "Precision: 0.6892198581560289 Recall: 0.2637201173389032 F1 Score 0.3814744822113443\n",
            "Precision: 0.6718275008837051 Recall: 0.25595448043531127 F1 Score 0.3706846271930671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3c89MwSqXot",
        "outputId": "a2014157-f5c1-4355-a543-21a0034d6f71"
      },
      "source": [
        "def read_item_names():\r\n",
        "    \"\"\"Read the u.item file from MovieLens 100-k dataset and return two\r\n",
        "    mappings to convert raw ids into movie names and movie names into raw ids.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\r\n",
        "    rid_to_name = {}\r\n",
        "    name_to_rid = {}\r\n",
        "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\r\n",
        "        for line in f:\r\n",
        "            line = line.split('|')\r\n",
        "            rid_to_name[line[0]] = line[1]\r\n",
        "            name_to_rid[line[1]] = line[0]\r\n",
        "\r\n",
        "    return rid_to_name, name_to_rid\r\n",
        "\r\n",
        "\r\n",
        "# First, train the algortihm to compute the similarities between items\r\n",
        "data = Dataset.load_builtin('ml-100k')\r\n",
        "trainset = data.build_full_trainset()\r\n",
        "sim_options = {'name': 'pearson_baseline', 'user_based': False}\r\n",
        "algo = KNNBasic(sim_options=sim_options)\r\n",
        "algo.fit(trainset)\r\n",
        "\r\n",
        "# Read the mappings raw id <-> movie name\r\n",
        "rid_to_name, name_to_rid = read_item_names()\r\n",
        "\r\n",
        "# Retrieve inner id of the movie Toy Story\r\n",
        "toy_story_raw_id = name_to_rid['Toy Story (1995)']\r\n",
        "toy_story_inner_id = algo.trainset.to_inner_iid(toy_story_raw_id)\r\n",
        "\r\n",
        "# Retrieve inner ids of the nearest neighbors of Toy Story.\r\n",
        "toy_story_neighbors = algo.get_neighbors(toy_story_inner_id, k=10)\r\n",
        "\r\n",
        "# Convert inner ids of the neighbors into names.\r\n",
        "toy_story_neighbors = (algo.trainset.to_raw_iid(inner_id)\r\n",
        "                       for inner_id in toy_story_neighbors)\r\n",
        "toy_story_neighbors = (rid_to_name[rid]\r\n",
        "                       for rid in toy_story_neighbors)\r\n",
        "\r\n",
        "print()\r\n",
        "print('The 10 nearest neighbors of Toy Story are:')\r\n",
        "for movie in toy_story_neighbors:\r\n",
        "    print(movie)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "\n",
            "The 10 nearest neighbors of Toy Story are:\n",
            "Beauty and the Beast (1991)\n",
            "Raiders of the Lost Ark (1981)\n",
            "That Thing You Do! (1996)\n",
            "Lion King, The (1994)\n",
            "Craft, The (1996)\n",
            "Liar Liar (1997)\n",
            "Aladdin (1992)\n",
            "Cool Hand Luke (1967)\n",
            "Winnie the Pooh and the Blustery Day (1968)\n",
            "Indiana Jones and the Last Crusade (1989)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vJz75GYq_Jb",
        "outputId": "5d8aeb8f-7170-4029-da0f-f8db76763f3b"
      },
      "source": [
        "# Compute predictions of the 'original' algorithm.\r\n",
        "predictions = algo.test(trainset.build_testset())\r\n",
        "\r\n",
        "# Dump algorithm and reload it.\r\n",
        "file_name = '/content/knn_basic_dump'\r\n",
        "dump.dump(file_name, algo=algo)\r\n",
        "_, loaded_algo = dump.load(file_name)\r\n",
        "\r\n",
        "# We now ensure that the algo is still the same by checking the predictions.\r\n",
        "predictions_loaded_algo = loaded_algo.test(trainset.build_testset())\r\n",
        "assert predictions == predictions_loaded_algo\r\n",
        "print('Predictions are the same')\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions are the same\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}